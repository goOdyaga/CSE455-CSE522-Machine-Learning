{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c7f4fee",
   "metadata": {},
   "source": [
    "# PART 1 -Decision Tree classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0ca6e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b271c4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, data, target):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.feature_index = None\n",
    "        self.threshold = None\n",
    "        self.value = None\n",
    "\n",
    "def entropy(y):\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "    probabilities = counts / len(y)\n",
    "    return -np.sum(probabilities * np.log2(probabilities + 1e-10))  # Adding a small epsilon to avoid log(0)\n",
    "\n",
    "def information_gain(y, y_left, y_right):\n",
    "    H_parent = entropy(y)\n",
    "    H_left = entropy(y_left)\n",
    "    H_right = entropy(y_right)\n",
    "\n",
    "    p_left = len(y_left) / len(y)\n",
    "    p_right = len(y_right) / len(y)\n",
    "\n",
    "    IG = H_parent - (p_left * H_left + p_right * H_right)\n",
    "    return IG\n",
    "\n",
    "def split_dataset(X, y, feature_index, threshold):\n",
    "    left_mask = X[:, feature_index] <= threshold\n",
    "    right_mask = ~left_mask\n",
    "    return X[left_mask], y[left_mask], X[right_mask], y[right_mask]\n",
    "\n",
    "def find_best_split(X, y):\n",
    "    m, n = X.shape\n",
    "    if m <= 1:\n",
    "        return None, None, None, None\n",
    "\n",
    "    num_classes = len(set(y))\n",
    "    best_ig = 0\n",
    "#     print(best_ig)\n",
    "    best_feature_index = None\n",
    "    best_threshold = None\n",
    "\n",
    "    for feature_index in range(n):\n",
    "        \n",
    "        thresholds = sorted(set(X[:, feature_index]))\n",
    "        for i in range(1, len(thresholds)):\n",
    "            threshold = (thresholds[i - 1] + thresholds[i]) / 2\n",
    "            X_left, y_left, X_right, y_right = split_dataset(X, y, feature_index, threshold)\n",
    "\n",
    "            if len(y_left) == 0 or len(y_right) == 0:\n",
    "                continue\n",
    "\n",
    "            ig = information_gain(y, y_left, y_right)\n",
    "            \n",
    "            if ig > best_ig:\n",
    "#                 print(ig)\n",
    "                best_ig = ig\n",
    "                best_feature_index = feature_index\n",
    "                best_threshold = threshold\n",
    "#     print(best_feature_index,best_threshold)\n",
    "    return best_feature_index, best_threshold\n",
    "\n",
    "def build_tree(X, y, depth=0, max_depth=33):\n",
    "#     print(f\"-->{depth}\")\n",
    "    if depth == max_depth or len(set(y)) == 1:\n",
    "        leaf = Node(data=None, target=y)\n",
    "        leaf.value = max(set(y), key=list(y).count)\n",
    "        return leaf\n",
    "\n",
    "    feature_index, threshold = find_best_split(X, y)\n",
    "#     print(threshold)\n",
    "    if feature_index is None:\n",
    "        leaf = Node(data=None, target=y)\n",
    "        leaf.value = max(set(y), key=list(y).count)\n",
    "        return leaf\n",
    "    X_left, y_left, X_right, y_right = split_dataset(X, y, feature_index, threshold)\n",
    "    node = Node(data=(feature_index, threshold), target=None)\n",
    "    node.left = build_tree(X_left, y_left, depth + 1, max_depth)\n",
    "    node.right = build_tree(X_right, y_right, depth + 1, max_depth)\n",
    "\n",
    "    return node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a23e539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tree, x):\n",
    "    if tree.value is not None:\n",
    "        # If the current node is a leaf node, return its predicted value\n",
    "        return tree.value\n",
    "    else:\n",
    "        # If the current node is not a leaf node, traverse to the appropriate child\n",
    "        feature_index, threshold = tree.data\n",
    "        if x[feature_index] <= threshold:\n",
    "            return predict(tree.left, x)\n",
    "        else:\n",
    "            return predict(tree.right, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75b1d227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smallest_prime_divisor(threshold, number):\n",
    "    if threshold >= number:\n",
    "        return \n",
    "    current_number = max(threshold + 1, 2)  # Ensure we start from at least 2\n",
    "    while current_number < number:\n",
    "        if  number % current_number == 0:\n",
    "            return current_number\n",
    "        current_number += 1\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88af6016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(X,y):\n",
    "        \n",
    "        indices = np.arange(len(y))\n",
    "\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        #compute the fold size\n",
    "        fold_size =  int(len(y)/smallest_prime_divisor(10,len(y)))\n",
    "\n",
    "        #determime folds\n",
    "        folds = [indices[i:i+smallest_prime_divisor(10,len(y))] for i in range(0, len(y), smallest_prime_divisor(10,len(y)))]\n",
    "        return folds,fold_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84eefcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setconfusion_matrix(predicted_label,true_label):\n",
    "    \n",
    "        confusion_matrix = np.zeros((2, 2))\n",
    "        for i in range(len(predicted_label)):\n",
    "            if predicted_label[i] == 1 and true_label[i] == 1:\n",
    "                confusion_matrix[1, 1] += 1  # True Positive\n",
    "            elif predicted_label[i] == 1 and true_label[i] == 0:\n",
    "                confusion_matrix[1, 0] += 1  # False Positive\n",
    "            elif predicted_label[i] == 0 and true_label[i] == 1:\n",
    "                confusion_matrix[0, 1] += 1  # False Negative\n",
    "            elif predicted_label[i] == 0 and true_label[i] == 0:\n",
    "                confusion_matrix[0, 0] += 1  # True Negative\n",
    "#         print(confusion_matrix)\n",
    "        return confusion_matrix\n",
    "def compute_matrix(confusion_matrix):\n",
    "    accuracy = (confusion_matrix[0, 0] + confusion_matrix[1, 1]) / np.sum(confusion_matrix)\n",
    "    precision = confusion_matrix[1, 1] / (confusion_matrix[1, 0] + confusion_matrix[1, 1])\n",
    "    recall = confusion_matrix[1, 1] / (confusion_matrix[0, 1] + confusion_matrix[1, 1])\n",
    "    return accuracy,precision,recall\n",
    "def calculate_average_metrics(accuracy_scores,precision_scores,recall_scores):\n",
    "    # Calculate the average metrics\n",
    "    average_accuracy = np.mean(accuracy_scores)\n",
    "    average_precision = np.mean(precision_scores)\n",
    "    average_recall = np.mean(recall_scores)\n",
    "    \n",
    "    return average_accuracy,average_precision,average_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71329a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"trial.csv\")\n",
    "# dataset_ = pd.read_csv(\"hour.csv\")\n",
    "df_numeric = dataset.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Replace NaN values with 0 \n",
    "dataset = df_numeric.fillna(0)\n",
    "# Extract features (X) by selecting all columns except the last one (labels)\n",
    "X = dataset.iloc[:, :-1].values\n",
    "\n",
    "# Extract labels (y) by selecting the last column\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "950e92d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds,fold_size=cross_validation(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "407a16b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix of the folds 1\n",
      "[[35.  0.]\n",
      " [ 0. 62.]]\n",
      "\n",
      "accuracy=1.0,precision=1.0,recall=1.0 of the folds 1\n",
      "\n",
      "Confusion matrix of the folds 2\n",
      "[[33.  0.]\n",
      " [ 0. 64.]]\n",
      "\n",
      "accuracy=1.0,precision=1.0,recall=1.0 of the folds 2\n",
      "\n",
      "Confusion matrix of the folds 3\n",
      "[[37.  0.]\n",
      " [ 0. 60.]]\n",
      "\n",
      "accuracy=1.0,precision=1.0,recall=1.0 of the folds 3\n",
      "\n",
      "Confusion matrix of the folds 4\n",
      "[[30.  0.]\n",
      " [ 0. 67.]]\n",
      "\n",
      "accuracy=1.0,precision=1.0,recall=1.0 of the folds 4\n",
      "\n",
      "Confusion matrix of the folds 5\n",
      "[[51.  0.]\n",
      " [ 0. 46.]]\n",
      "\n",
      "accuracy=1.0,precision=1.0,recall=1.0 of the folds 5\n",
      "\n",
      "Confusion matrix of the folds 6\n",
      "[[33.  0.]\n",
      " [ 0. 64.]]\n",
      "\n",
      "accuracy=1.0,precision=1.0,recall=1.0 of the folds 6\n",
      "\n",
      "Confusion matrix of the folds 7\n",
      "[[27.  0.]\n",
      " [ 0. 70.]]\n",
      "\n",
      "accuracy=1.0,precision=1.0,recall=1.0 of the folds 7\n",
      "\n",
      "Confusion matrix of the folds 8\n",
      "[[44.  0.]\n",
      " [ 0. 53.]]\n",
      "\n",
      "accuracy=1.0,precision=1.0,recall=1.0 of the folds 8\n",
      "\n",
      "\n",
      "average of the accuracy=1.0,precision=1.0,recall=1.0 \n",
      "\n",
      "Total run time is 2.650033712387085\n"
     ]
    }
   ],
   "source": [
    "recall_scores=[]\n",
    "\n",
    "precision_scores=[]\n",
    "\n",
    "accuracy_scores=[]\n",
    "start_time = time.time()\n",
    "for i in range(fold_size):\n",
    "    \n",
    "    test_data = folds[i]\n",
    "\n",
    "    train_data = np.concatenate([f for j, f in enumerate(folds) if j != i])\n",
    "    \n",
    "    X_train,y_train=X[train_data],y[train_data]\n",
    "    \n",
    "    dt_model=build_tree(X_train,y_train,0,3)\n",
    "    \n",
    "    X_test,y_test=X[test_data],y[test_data]\n",
    "    \n",
    "    predicitons=[predict(dt_model, sample) for sample in X_test]\n",
    "    \n",
    "    predictions=np.array(predicitons)\n",
    "\n",
    "    confusion_matrix=setconfusion_matrix(predictions,y_test)\n",
    "    print(f\"Confusion matrix of the folds {i+1}\")\n",
    "    print(confusion_matrix)\n",
    "    accuracy,precision,recall=compute_matrix(confusion_matrix)\n",
    "    print(f\"\\naccuracy={accuracy},precision={precision},recall={recall} of the folds {i+1}\\n\")\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "    precision_scores.append(precision)\n",
    "    \n",
    "    recall_scores.append(recall)\n",
    "\n",
    "average_accuracy,average_precision,average_recall=calculate_average_metrics(accuracy_scores,precision_scores,recall_scores)\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "totTime = end_time - start_time   \n",
    "print(f\"\\naverage of the accuracy={average_accuracy},precision={average_precision},recall={average_recall} \\n\")\n",
    "print(f\"Total run time is {totTime}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9caf58",
   "metadata": {},
   "source": [
    "# RESULT OF THE DECISION TREE BASE ON THE MODEL CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b36fdd",
   "metadata": {},
   "source": [
    "--> I have implemented decision tree for the classification. Result of the this model is very well.Therefore I couldnt trust result\n",
    ". Then I have check attribute and threshold which are vest information gain. next I convert some data point to TP and FN. Model could find them and result have been change with these change. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63615f86",
   "metadata": {},
   "source": [
    "# PART 2 -Decision Tree REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "998c3493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_squared_residuals(y):\n",
    "    if len(y) == 0:\n",
    "        return 0\n",
    "    mean = np.mean(y)\n",
    "    return np.sum((y - mean) ** 2)\n",
    "\n",
    "def total_squared_residuals(y_left, y_right):\n",
    "    return sum_squared_residuals(y_left) + sum_squared_residuals(y_right)\n",
    "def find_best_split_reg(X, y):\n",
    "    m, n = X.shape\n",
    "    if m <= 1:\n",
    "        return None, None, None, None\n",
    "\n",
    "    best_mse = float('inf')\n",
    "    best_feature_index = None\n",
    "    best_threshold = None\n",
    "\n",
    "    for feature_index in range(n):\n",
    "        thresholds = sorted(set(X[:, feature_index]))\n",
    "        for i in range(1, len(thresholds)):\n",
    "            threshold = (thresholds[i - 1] + thresholds[i]) / 2\n",
    "            X_left, y_left, X_right, y_right = split_dataset(X, y, feature_index, threshold)\n",
    "\n",
    "            if len(y_left) == 0 or len(y_right) == 0:\n",
    "                continue\n",
    "\n",
    "            mse = total_squared_residuals(y_left, y_right)\n",
    "\n",
    "            if mse < best_mse:\n",
    "                best_mse = mse\n",
    "                best_feature_index = feature_index\n",
    "                best_threshold = threshold\n",
    "\n",
    "    return best_feature_index, best_threshold\n",
    "\n",
    "def build_tree_reg(X, y, depth=0, max_depth=None):\n",
    "    if depth == max_depth or len(set(y)) == 4:\n",
    "        leaf = Node(data=None, target=y)\n",
    "        leaf.value = np.mean(y)\n",
    "        return leaf\n",
    "\n",
    "    feature_index, threshold = find_best_split_reg(X, y)\n",
    "\n",
    "    if feature_index is None:\n",
    "        leaf = Node(data=None, target=y)\n",
    "        leaf.value = np.mean(y)\n",
    "        return leaf\n",
    "\n",
    "    X_left, y_left, X_right, y_right = split_dataset(X, y, feature_index, threshold)\n",
    "\n",
    "    node = Node(data=(feature_index, threshold), target=None)\n",
    "    node.left = build_tree(X_left, y_left, depth + 1, max_depth)\n",
    "    node.right = build_tree(X_right, y_right, depth + 1, max_depth)\n",
    "\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7674208",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ = pd.read_csv(\"hour.csv\")\n",
    "df_numeric_ = dataset_.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Replace NaN values with 0 \n",
    "dataset_ = df_numeric_.fillna(0)\n",
    "# Extract features (X) by selecting all columns except the last one (labels)\n",
    "X_ = dataset_.iloc[:, :-1].values\n",
    "\n",
    "# Extract labels (y) by selecting the last column\n",
    "y_ = dataset_.iloc[:, -1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad3450d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_,fold_size_=cross_validation(X_,y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36cc4f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST FOLD 1\n",
      "MSE(Mean Squared Error) = 10007.973070947695\n",
      "Run time of Fold 1\n",
      "41.49535632133484\n",
      "TEST FOLD 2\n",
      "MSE(Mean Squared Error) = 10263.105126877266\n",
      "Run time of Fold 2\n",
      "38.48461723327637\n",
      "TEST FOLD 3\n",
      "MSE(Mean Squared Error) = 7625.818228896945\n",
      "Run time of Fold 3\n",
      "38.46780252456665\n",
      "TEST FOLD 4\n",
      "MSE(Mean Squared Error) = 8595.917659243914\n",
      "Run time of Fold 4\n",
      "36.7067186832428\n",
      "TEST FOLD 5\n",
      "MSE(Mean Squared Error) = 9013.859658208183\n",
      "Run time of Fold 5\n",
      "39.23066735267639\n",
      "TEST FOLD 6\n",
      "MSE(Mean Squared Error) = 10004.28586224754\n",
      "Run time of Fold 6\n",
      "36.5459418296814\n",
      "TEST FOLD 7\n",
      "MSE(Mean Squared Error) = 8155.599689280166\n",
      "Run time of Fold 7\n",
      "36.57511830329895\n",
      "TEST FOLD 8\n",
      "MSE(Mean Squared Error) = 9409.042982910409\n",
      "Run time of Fold 8\n",
      "36.52086901664734\n",
      "TEST FOLD 9\n",
      "MSE(Mean Squared Error) = 8733.885551527706\n",
      "Run time of Fold 9\n",
      "36.35563111305237\n",
      "Average MSE of DECISION TREE = 9089.943092237758\n",
      "Total run time is 2.650033712387085\n"
     ]
    }
   ],
   "source": [
    "start_time_ = time.time()\n",
    "mse_scores=[]\n",
    "for i in range(fold_size_):\n",
    "    start_time_1 = time.time()\n",
    "    test_data = folds_[i]\n",
    "\n",
    "    train_data = np.concatenate([f for j, f in enumerate(folds_) if j != i])\n",
    "    \n",
    "    X_train,y_train=X_[train_data],y_[train_data]\n",
    "    \n",
    "    dt_model=build_tree_reg(X_train,y_train,0,2)\n",
    "    \n",
    "    X_test,y_test=X_[test_data],y_[test_data]\n",
    "\n",
    "    predicitons=[predict(dt_model, sample) for sample in X_test]  \n",
    "    predictions=np.array(predicitons)\n",
    "    mse = np.mean((predictions - y_test) ** 2)\n",
    "    print(f\"TEST FOLD {i+1}\")\n",
    "    print(f\"MSE(Mean Squared Error) = {mse}\")\n",
    "    mse_scores.append(mse)\n",
    "    end_time_1 = time.time()\n",
    "    totTime_1 = end_time_1 - start_time_1   \n",
    "    print(f\"Run time of Fold {i+1}\")\n",
    "    print(totTime_1)\n",
    "    \n",
    "    \n",
    "end_time_ = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "totTime_ = end_time - start_time   \n",
    "average_mse = np.mean(mse_scores)\n",
    "print(f\"Average MSE of DECISION TREE = {average_mse}\")\n",
    "print(f\"Total run time is {totTime}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cd2995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "260083d4",
   "metadata": {},
   "source": [
    "# RESULT OF THE DECISION TREE BASE ON THE MODEL REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafa5d73",
   "metadata": {},
   "source": [
    "In this model I Have implemented decision tree for the regression problem.I aim to find to best split and because of that I have used SSR(Sum Squared Residuals). I have used TSE(Total Squared Error) but its results are worst than SSR. Therefore I have chosen SSR in my model.My dataset it too big for regression. So That my run time is too bad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e1452e",
   "metadata": {},
   "source": [
    "# PART 3 - Implementation Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab4a1c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Function for bootstrapping\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def bootstrap_sample(dataset, labels,X_test, num_samples=None, num_features=None):\n",
    "    \n",
    "    if num_samples is None:\n",
    "        num_samples = len(dataset)\n",
    "\n",
    "    if num_features is None:\n",
    "        num_features = int(len(dataset[0])*0.5)\n",
    "    \n",
    "    indices = np.random.choice(len(dataset), size=num_samples, replace=True)\n",
    "    bootstrap_dataset = dataset[indices]\n",
    "    bootstrap_labels = labels[indices]\n",
    "\n",
    "    selected_features = np.random.choice(dataset.shape[1], num_features, replace=False)\n",
    "      \n",
    "    bootstrap_dataset = bootstrap_dataset[:, selected_features]\n",
    "    X_test=X_test[:, selected_features]\n",
    "    return X_test,bootstrap_dataset, bootstrap_labels\n",
    "\n",
    "# Function for bagging\n",
    "def build_rdf(X, y,X_test,test, num_models):\n",
    "    all_predictions = []\n",
    "    for _ in range(num_models):\n",
    "        test1,X_sampled, y_sampled = bootstrap_sample(X,y,X_test)\n",
    "        model = build_tree(X_sampled,y_sampled,0,33)\n",
    "        predictions_for_tree = [predict(model, sample) for sample in test1]\n",
    "        all_predictions.append(predictions_for_tree)\n",
    "        \n",
    "    result_array = np.apply_along_axis(custom_mode, axis=0, arr=all_predictions)\n",
    "\n",
    "    confusion_matrix=setconfusion_matrix(result_array,test)\n",
    "    \n",
    "    accuracy,precision,recall=compute_matrix(confusion_matrix)\n",
    "    return accuracy,precision,recall\n",
    "\n",
    "def build_rdf_reg(X, y,X_test,test, num_models):\n",
    "    all_predictions = []\n",
    "    for _ in range(num_models):\n",
    "        test1,X_sampled, y_sampled = bootstrap_sample(X,y,X_test)\n",
    "        model = build_tree_reg(X_sampled,y_sampled,0,3)\n",
    "        predictions_for_tree = [predict(model, sample) for sample in test1]\n",
    "        all_predictions.append(predictions_for_tree)\n",
    "    \n",
    "    return all_predictions\n",
    "\n",
    "def custom_mode(arr):\n",
    "    unique_elements, counts = np.unique(arr, return_counts=True)\n",
    "    most_frequent_index = np.argmax(counts)\n",
    "    return unique_elements[most_frequent_index]\n",
    "\n",
    "#     result_array = np.apply_along_axis(custom_mode, axis=0, arr=all_predictions_array)\n",
    "\n",
    "def predict_rdf(rdf, X, options):\n",
    "    all_predictions = []\n",
    "\n",
    "    # Iterate through each tree and get predictions\n",
    "    for tree in rdf:\n",
    "        predictions_for_tree = [predict(tree, sample) for sample in X]\n",
    "        all_predictions.append(predictions_for_tree)\n",
    "    return all_predictions\n",
    "\n",
    "def weights_ofTree(models,X,y):\n",
    "    \n",
    "    accuricies=[]\n",
    "    for tree in models:\n",
    "        #find predictions of the each tree\n",
    "        predictions_for_tree = [predict(tree, sample) for sample in X]\n",
    "            \n",
    "        #set confusion matrix of the each tree    \n",
    "        confusion_matrix=setconfusion_matrix(predictions_for_tree,y)\n",
    "        \n",
    "        accuracy = (confusion_matrix[0, 0] + confusion_matrix[1, 1]) / np.sum(confusion_matrix)\n",
    "        \n",
    "        accuricies.append(accuracy)\n",
    "        \n",
    "    return np.array(accuricies) / sum(accuricies)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "faf17058",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy=1.0,precision=1.0,recall=1.0 of the folds 1\n",
      "\n",
      "\n",
      "accuracy=1.0,precision=1.0,recall=1.0 of the folds 2\n",
      "\n",
      "\n",
      "accuracy=0.979381443298969,precision=1.0,recall=0.9666666666666667 of the folds 3\n",
      "\n",
      "\n",
      "accuracy=1.0,precision=1.0,recall=1.0 of the folds 4\n",
      "\n",
      "\n",
      "accuracy=0.9896907216494846,precision=1.0,recall=0.9782608695652174 of the folds 5\n",
      "\n",
      "\n",
      "accuracy=1.0,precision=1.0,recall=1.0 of the folds 6\n",
      "\n",
      "\n",
      "accuracy=0.9587628865979382,precision=1.0,recall=0.9428571428571428 of the folds 7\n",
      "\n",
      "\n",
      "accuracy=1.0,precision=1.0,recall=1.0 of the folds 8\n",
      "\n",
      "\n",
      "average of the accuracy=0.990979381443299,precision=1.0,recall=0.9859730848861283 \n",
      "\n",
      "Total run time is 17.504173278808594\n",
      "Total run time is 17.504173278808594\n"
     ]
    }
   ],
   "source": [
    "\n",
    "recall_scores=[]\n",
    "\n",
    "precision_scores=[]\n",
    "\n",
    "accuracy_scores=[]\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(fold_size):\n",
    "    \n",
    "    test_data = folds[i]\n",
    "\n",
    "    train_data = np.concatenate([f for j, f in enumerate(folds) if j != i])\n",
    "    \n",
    "    X_train,y_train=X[train_data],y[train_data]\n",
    "    \n",
    "    X_test,y_test=X[test_data],y[test_data]\n",
    "    \n",
    "    accuracy,precision,recall=build_rdf(X_train,y_train,X_test,y_test,10)\n",
    "    \n",
    "    print(f\"\\naccuracy={accuracy},precision={precision},recall={recall} of the folds {i+1}\\n\")\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "    precision_scores.append(precision)\n",
    "    \n",
    "    recall_scores.append(recall)\n",
    "\n",
    "average_accuracy,average_precision,average_recall=calculate_average_metrics(accuracy_scores,precision_scores,recall_scores)\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "totTime = end_time - start_time   \n",
    "print(f\"\\naverage of the accuracy={average_accuracy},precision={average_precision},recall={average_recall} \\n\")\n",
    "print(f\"Total run time is {totTime}\")\n",
    "    \n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "totTime = end_time - start_time   \n",
    "# print(f\"\\naverage of the accuracy={average} \\n\")\n",
    "print(f\"Total run time is {totTime}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213df135",
   "metadata": {},
   "source": [
    "# Random Forest Classificaton problem Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9415ea68",
   "metadata": {},
   "source": [
    "In this essemble model, firstly I obtained new dataset by bootstrapping method. Then for each dataset I have use random data distrubiiton . I use half of the total attribution  and create 100 tree for random forest. at the essemble method I have obtain better accuracy and recall when I compare it the single decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97619ad",
   "metadata": {},
   "source": [
    "# PART 4 - Implementation Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7328d23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of folds 1 : 7469.992687985499\n",
      "Run time of Fold 1\n",
      "1171.2392075061798\n",
      "MSE of folds 2 : 7818.110715898499\n",
      "Run time of Fold 2\n",
      "1256.55770277977\n",
      "MSE of folds 3 : 7773.846053599171\n",
      "Run time of Fold 3\n",
      "2397.3146402835846\n",
      "MSE of folds 4 : 9053.616383635423\n",
      "Run time of Fold 4\n",
      "2944.1461493968964\n",
      "MSE of folds 5 : 7814.925433661316\n",
      "Run time of Fold 5\n",
      "30545.2113802433\n",
      "MSE of folds 6 : 10495.882805644744\n",
      "Run time of Fold 6\n",
      "1096.4526777267456\n",
      "MSE of folds 7 : 8889.403350595545\n",
      "Run time of Fold 7\n",
      "1224.321694612503\n",
      "MSE of folds 8 : 7440.391503158985\n",
      "Run time of Fold 8\n",
      "1387.5264151096344\n",
      "MSE of folds 9 : 6314.653501398239\n",
      "Run time of Fold 9\n",
      "1304.5333626270294\n",
      "Average MSE of DECISION TREE = 8118.980270619712\n",
      "Total run time is 17.504173278808594\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "start_time_ = time.time()\n",
    "mse_scores=[]\n",
    "for i in range(fold_size_):\n",
    "    start_time_1 = time.time()\n",
    "    test_data = folds_[i]\n",
    "\n",
    "    train_data = np.concatenate([f for j, f in enumerate(folds_) if j != i])\n",
    "    \n",
    "    X_train,y_train=X_[train_data],y_[train_data]\n",
    "    \n",
    "    X_test,y_test=X_[test_data],y_[test_data]\n",
    "    \n",
    "    predicitons=build_rdf_reg(X_train,y_train,X_test,y_test,100)\n",
    "    \n",
    "    predictions = np.array(predicitons)\n",
    "\n",
    "    \n",
    "    \n",
    "    aggregated_predictions = [sum(pred) / len(pred) for pred in zip(*predictions)]\n",
    "    \n",
    "    mse = mean_squared_error(y_test, aggregated_predictions)\n",
    "    mse_scores.append(mse)\n",
    "    print(f\"MSE of folds {i+1} : {mse}\")\n",
    "    end_time_1 = time.time()\n",
    "    totTime_1 = end_time_1 - start_time_1   \n",
    "    print(f\"Run time of Fold {i+1}\")\n",
    "    print(totTime_1)\n",
    "    \n",
    "    \n",
    "end_time_ = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "totTime_ = end_time - start_time   \n",
    "average_mse = np.mean(mse_scores)\n",
    "print(f\"Average MSE of DECISION TREE = {average_mse}\")\n",
    "print(f\"Total run time is {totTime}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e890a50",
   "metadata": {},
   "source": [
    "# RESULT OF REGRESSIN BASED ON RANDOM FOREST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c71820",
   "metadata": {},
   "source": [
    "In this model I have implemented Random forest for regression. But it is to hard to create decision tree for regression. furthermore when we use random forest for regression it's run time will bee too bad. I dont choose random forest fpr regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73b01e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

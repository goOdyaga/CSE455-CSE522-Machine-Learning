{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c7f4fee",
   "metadata": {},
   "source": [
    "# PART 1 -Decision Tree classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0ca6e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b271c4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, data, target):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.feature_index = None\n",
    "        self.threshold = None\n",
    "        self.value = None\n",
    "\n",
    "def entropy(y):\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "    probabilities = counts / len(y)\n",
    "    return -np.sum(probabilities * np.log2(probabilities + 1e-10))  # Adding a small epsilon to avoid log(0)\n",
    "\n",
    "def information_gain(y, y_left, y_right):\n",
    "    H_parent = entropy(y)\n",
    "    H_left = entropy(y_left)\n",
    "    H_right = entropy(y_right)\n",
    "\n",
    "    p_left = len(y_left) / len(y)\n",
    "    p_right = len(y_right) / len(y)\n",
    "\n",
    "    IG = H_parent - (p_left * H_left + p_right * H_right)\n",
    "    return IG\n",
    "\n",
    "def split_dataset(X, y, feature_index, threshold):\n",
    "    left_mask = X[:, feature_index] <= threshold\n",
    "    right_mask = ~left_mask\n",
    "    return X[left_mask], y[left_mask], X[right_mask], y[right_mask]\n",
    "\n",
    "def find_best_split(X, y):\n",
    "    m, n = X.shape\n",
    "    if m <= 1:\n",
    "        return None, None, None, None\n",
    "\n",
    "    num_classes = len(set(y))\n",
    "    best_ig = 0\n",
    "#     print(best_ig)\n",
    "    best_feature_index = None\n",
    "    best_threshold = None\n",
    "\n",
    "    for feature_index in range(n):\n",
    "        \n",
    "        thresholds = sorted(set(X[:, feature_index]))\n",
    "        for i in range(1, len(thresholds)):\n",
    "            threshold = (thresholds[i - 1] + thresholds[i]) / 2\n",
    "            X_left, y_left, X_right, y_right = split_dataset(X, y, feature_index, threshold)\n",
    "\n",
    "            if len(y_left) == 0 or len(y_right) == 0:\n",
    "                continue\n",
    "\n",
    "            ig = information_gain(y, y_left, y_right)\n",
    "            \n",
    "            if ig > best_ig:\n",
    "#                 print(ig)\n",
    "                best_ig = ig\n",
    "                best_feature_index = feature_index\n",
    "                best_threshold = threshold\n",
    "#     print(best_feature_index,best_threshold)\n",
    "    return best_feature_index, best_threshold\n",
    "\n",
    "def build_tree(X, y, depth=0, max_depth=3):\n",
    "    if depth == max_depth or len(set(y)) == 1:\n",
    "        leaf = Node(data=None, target=y)\n",
    "        leaf.value = max(set(y), key=list(y).count)\n",
    "        return leaf\n",
    "\n",
    "    feature_index, threshold = find_best_split(X, y)\n",
    "    if feature_index is None:\n",
    "        leaf = Node(data=None, target=y)\n",
    "        leaf.value = max(set(y), key=list(y).count)\n",
    "        return leaf\n",
    "    X_left, y_left, X_right, y_right = split_dataset(X, y, feature_index, threshold)\n",
    "    node = Node(data=(feature_index, threshold), target=None)\n",
    "    node.left = build_tree(X_left, y_left, depth + 1, max_depth)\n",
    "    node.right = build_tree(X_right, y_right, depth + 1, max_depth)\n",
    "\n",
    "    return node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a23e539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tree, x):\n",
    "    if tree.value is not None:\n",
    "        # If the current node is a leaf node, return its predicted value\n",
    "        return tree.value\n",
    "    else:\n",
    "        # If the current node is not a leaf node, traverse to the appropriate child\n",
    "        feature_index, threshold = tree.data\n",
    "        if x[feature_index] <= threshold:\n",
    "            return predict(tree.left, x)\n",
    "        else:\n",
    "            return predict(tree.right, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75b1d227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smallest_prime_divisor(threshold, number):\n",
    "        if threshold >= number:\n",
    "            return \n",
    "        current_number = max(threshold + 1, 2)  # Ensure we start from at least 2\n",
    "        while current_number < number:\n",
    "            if  number % current_number == 0:\n",
    "                return current_number\n",
    "            current_number += 1\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88af6016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(X,y):\n",
    "        \n",
    "        indices = np.arange(len(y))\n",
    "\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        #compute the fold size\n",
    "        fold_size =  int(len(y)/smallest_prime_divisor(10,len(y)))\n",
    "\n",
    "        #determime folds\n",
    "        folds = [indices[i:i+smallest_prime_divisor(10,len(y))] for i in range(0, len(y), smallest_prime_divisor(10,len(y)))]\n",
    "        return folds,fold_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84eefcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setconfusion_matrix(predicted_label,true_label):\n",
    "    \n",
    "        confusion_matrix = np.zeros((2, 2))\n",
    "        for i in range(len(predicted_label)):\n",
    "            if predicted_label[i] == 1 and true_label[i] == 1:\n",
    "                confusion_matrix[1, 1] += 1  # True Positive\n",
    "            elif predicted_label[i] == 1 and true_label[i] == 0:\n",
    "                confusion_matrix[1, 0] += 1  # False Positive\n",
    "            elif predicted_label[i] == 0 and true_label[i] == 1:\n",
    "                confusion_matrix[0, 1] += 1  # False Negative\n",
    "            elif predicted_label[i] == 0 and true_label[i] == 0:\n",
    "                confusion_matrix[0, 0] += 1  # True Negative\n",
    "#         print(confusion_matrix)\n",
    "        return confusion_matrix\n",
    "def compute_matrix(confusion_matrix):\n",
    "    accuracy = (confusion_matrix[0, 0] + confusion_matrix[1, 1]) / np.sum(confusion_matrix)\n",
    "    precision = confusion_matrix[1, 1] / (confusion_matrix[1, 0] + confusion_matrix[1, 1])\n",
    "    recall = confusion_matrix[1, 1] / (confusion_matrix[0, 1] + confusion_matrix[1, 1])\n",
    "    return accuracy,precision,recall\n",
    "def calculate_average_metrics(accuracy_scores,precision_scores,recall_scores):\n",
    "    # Calculate the average metrics\n",
    "    average_accuracy = np.mean(accuracy_scores)\n",
    "    average_precision = np.mean(precision_scores)\n",
    "    average_recall = np.mean(recall_scores)\n",
    "    \n",
    "    return average_accuracy,average_precision,average_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71329a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"trial.csv\")\n",
    "# dataset_ = pd.read_csv(\"hour.csv\")\n",
    "df_numeric = dataset.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Replace NaN values with 0 \n",
    "dataset = df_numeric.fillna(0)\n",
    "# Extract features (X) by selecting all columns except the last one (labels)\n",
    "X = dataset.iloc[:, :-1].values\n",
    "\n",
    "# Extract labels (y) by selecting the last column\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "950e92d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds,fold_size=cross_validation(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "407a16b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix of the folds 1\n",
      "[[38.  0.]\n",
      " [ 0. 59.]]\n",
      "\n",
      "accuracy=1.0,precision=1.0,recall=1.0 of the folds 1\n",
      "\n",
      "Confusion matrix of the folds 2\n",
      "[[41.  0.]\n",
      " [ 0. 56.]]\n",
      "\n",
      "accuracy=1.0,precision=1.0,recall=1.0 of the folds 2\n",
      "\n",
      "Confusion matrix of the folds 3\n",
      "[[40.  0.]\n",
      " [ 0. 57.]]\n",
      "\n",
      "accuracy=1.0,precision=1.0,recall=1.0 of the folds 3\n",
      "\n",
      "Confusion matrix of the folds 4\n",
      "[[33.  0.]\n",
      " [ 0. 64.]]\n",
      "\n",
      "accuracy=1.0,precision=1.0,recall=1.0 of the folds 4\n",
      "\n",
      "Confusion matrix of the folds 5\n",
      "[[32.  0.]\n",
      " [ 0. 65.]]\n",
      "\n",
      "accuracy=1.0,precision=1.0,recall=1.0 of the folds 5\n",
      "\n",
      "Confusion matrix of the folds 6\n",
      "[[37.  0.]\n",
      " [ 0. 60.]]\n",
      "\n",
      "accuracy=1.0,precision=1.0,recall=1.0 of the folds 6\n",
      "\n",
      "Confusion matrix of the folds 7\n",
      "[[32.  0.]\n",
      " [ 0. 65.]]\n",
      "\n",
      "accuracy=1.0,precision=1.0,recall=1.0 of the folds 7\n",
      "\n",
      "Confusion matrix of the folds 8\n",
      "[[37.  0.]\n",
      " [ 0. 60.]]\n",
      "\n",
      "accuracy=1.0,precision=1.0,recall=1.0 of the folds 8\n",
      "\n",
      "\n",
      "average of the accuracy=1.0,precision=1.0,recall=1.0 \n",
      "\n",
      "Total run time is 1.427931785583496\n"
     ]
    }
   ],
   "source": [
    "recall_scores=[]\n",
    "\n",
    "precision_scores=[]\n",
    "\n",
    "accuracy_scores=[]\n",
    "start_time = time.time()\n",
    "for i in range(fold_size):\n",
    "    \n",
    "    test_data = folds[i]\n",
    "\n",
    "    train_data = np.concatenate([f for j, f in enumerate(folds) if j != i])\n",
    "    \n",
    "    X_train,y_train=X[train_data],y[train_data]\n",
    "    \n",
    "    dt_model=build_tree(X_train,y_train,0,3)\n",
    "    \n",
    "    X_test,y_test=X[test_data],y[test_data]\n",
    "    \n",
    "    predicitons=[predict(dt_model, sample) for sample in X_test]\n",
    "    \n",
    "    predictions=np.array(predicitons)\n",
    "\n",
    "    confusion_matrix=setconfusion_matrix(predictions,y_test)\n",
    "    print(f\"Confusion matrix of the folds {i+1}\")\n",
    "    print(confusion_matrix)\n",
    "    accuracy,precision,recall=compute_matrix(confusion_matrix)\n",
    "    print(f\"\\naccuracy={accuracy},precision={precision},recall={recall} of the folds {i+1}\\n\")\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "    precision_scores.append(precision)\n",
    "    \n",
    "    recall_scores.append(recall)\n",
    "\n",
    "average_accuracy,average_precision,average_recall=calculate_average_metrics(accuracy_scores,precision_scores,recall_scores)\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "totTime = end_time - start_time   \n",
    "print(f\"\\naverage of the accuracy={average_accuracy},precision={average_precision},recall={average_recall} \\n\")\n",
    "print(f\"Total run time is {totTime}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9caf58",
   "metadata": {},
   "source": [
    "# RESULT OF THE DECISION TREE BASE ON THE MODEL CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b36fdd",
   "metadata": {},
   "source": [
    "--> I have implemented decision tree for the classification. Result of the this model is very well.Therefore I couldnt trust result\n",
    ". Then I have check attribute and threshold which are vest information gain. next I convert some data point to TP and FN. Model could find them and result have been change with these change. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63615f86",
   "metadata": {},
   "source": [
    "# PART 2 -Decision Tree REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "998c3493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_squared_residuals(y):\n",
    "    if len(y) == 0:\n",
    "        return 0\n",
    "    mean = np.mean(y)\n",
    "    return np.sum((y - mean) ** 2)\n",
    "\n",
    "def total_squared_residuals(y_left, y_right):\n",
    "    return sum_squared_residuals(y_left) + sum_squared_residuals(y_right)\n",
    "def find_best_split_reg(X, y):\n",
    "    m, n = X.shape\n",
    "    if m <= 1:\n",
    "        return None, None, None, None\n",
    "\n",
    "    best_mse = float('inf')\n",
    "    best_feature_index = None\n",
    "    best_threshold = None\n",
    "\n",
    "    for feature_index in range(n):\n",
    "        thresholds = sorted(set(X[:, feature_index]))\n",
    "        for i in range(1, len(thresholds)):\n",
    "            threshold = (thresholds[i - 1] + thresholds[i]) / 2\n",
    "            X_left, y_left, X_right, y_right = split_dataset(X, y, feature_index, threshold)\n",
    "\n",
    "            if len(y_left) == 0 or len(y_right) == 0:\n",
    "                continue\n",
    "\n",
    "            mse = total_squared_residuals(y_left, y_right)\n",
    "\n",
    "            if mse < best_mse:\n",
    "                best_mse = mse\n",
    "                best_feature_index = feature_index\n",
    "                best_threshold = threshold\n",
    "\n",
    "    return best_feature_index, best_threshold\n",
    "\n",
    "def build_tree_reg(X, y, depth=0, max_depth=None):\n",
    "    if depth == max_depth or len(set(y)) == 1:\n",
    "        leaf = Node(data=None, target=y)\n",
    "        leaf.value = np.mean(y)\n",
    "        return leaf\n",
    "\n",
    "    feature_index, threshold = find_best_split_reg(X, y)\n",
    "\n",
    "    if feature_index is None:\n",
    "        leaf = Node(data=None, target=y)\n",
    "        leaf.value = np.mean(y)\n",
    "        return leaf\n",
    "\n",
    "    X_left, y_left, X_right, y_right = split_dataset(X, y, feature_index, threshold)\n",
    "\n",
    "    node = Node(data=(feature_index, threshold), target=None)\n",
    "    node.left = build_tree(X_left, y_left, depth + 1, max_depth)\n",
    "    node.right = build_tree(X_right, y_right, depth + 1, max_depth)\n",
    "\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7674208",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ = pd.read_csv(\"hour.csv\")\n",
    "df_numeric_ = dataset_.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Replace NaN values with 0 \n",
    "dataset_ = df_numeric_.fillna(0)\n",
    "# Extract features (X) by selecting all columns except the last one (labels)\n",
    "X_ = dataset_.iloc[:, :-1].values\n",
    "\n",
    "# Extract labels (y) by selecting the last column\n",
    "y_ = dataset_.iloc[:, -1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad3450d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_,fold_size_=cross_validation(X_,y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36cc4f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST FOLD 1\n",
      "MSE(Mean Squared Error) = 10094.382185396167\n",
      "Run time of Fold 1\n",
      "37.54422330856323\n",
      "TEST FOLD 2\n",
      "MSE(Mean Squared Error) = 9470.734334541688\n",
      "Run time of Fold 2\n",
      "37.43557286262512\n",
      "TEST FOLD 3\n",
      "MSE(Mean Squared Error) = 9230.970999482133\n",
      "Run time of Fold 3\n",
      "39.77035474777222\n",
      "TEST FOLD 4\n",
      "MSE(Mean Squared Error) = 8970.467115484205\n",
      "Run time of Fold 4\n",
      "39.1108820438385\n",
      "TEST FOLD 5\n",
      "MSE(Mean Squared Error) = 8747.392024857587\n",
      "Run time of Fold 5\n",
      "39.10930776596069\n",
      "TEST FOLD 6\n",
      "MSE(Mean Squared Error) = 9286.211807353702\n",
      "Run time of Fold 6\n",
      "40.92438578605652\n",
      "TEST FOLD 7\n",
      "MSE(Mean Squared Error) = 9717.697566027964\n",
      "Run time of Fold 7\n",
      "41.14089107513428\n",
      "TEST FOLD 8\n",
      "MSE(Mean Squared Error) = 7199.672190574832\n",
      "Run time of Fold 8\n",
      "38.20404577255249\n",
      "TEST FOLD 9\n",
      "MSE(Mean Squared Error) = 7946.398757120663\n",
      "Run time of Fold 9\n",
      "37.387815713882446\n",
      "Average MSE of DECISION TREE = 8962.65855342655\n",
      "Total run time is 1.427931785583496\n"
     ]
    }
   ],
   "source": [
    "start_time_ = time.time()\n",
    "mse_scores=[]\n",
    "for i in range(fold_size_):\n",
    "    start_time_1 = time.time()\n",
    "    test_data = folds_[i]\n",
    "\n",
    "    train_data = np.concatenate([f for j, f in enumerate(folds_) if j != i])\n",
    "    \n",
    "    X_train,y_train=X_[train_data],y_[train_data]\n",
    "    \n",
    "    dt_model=build_tree_reg(X_train,y_train,0,2)\n",
    "    \n",
    "    X_test,y_test=X_[test_data],y_[test_data]\n",
    "\n",
    "    predicitons=[predict(dt_model, sample) for sample in X_test]  \n",
    "    predictions=np.array(predicitons)\n",
    "    mse = np.mean((predictions - y_test) ** 2)\n",
    "    print(f\"TEST FOLD {i+1}\")\n",
    "    print(f\"MSE(Mean Squared Error) = {mse}\")\n",
    "    mse_scores.append(mse)\n",
    "    end_time_1 = time.time()\n",
    "    totTime_1 = end_time_1 - start_time_1   \n",
    "    print(f\"Run time of Fold {i+1}\")\n",
    "    print(totTime_1)\n",
    "    \n",
    "    \n",
    "end_time_ = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "totTime_ = end_time - start_time   \n",
    "average_mse = np.mean(mse_scores)\n",
    "print(f\"Average MSE of DECISION TREE = {average_mse}\")\n",
    "print(f\"Total run time is {totTime}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b886f9f",
   "metadata": {},
   "source": [
    "# RESULT OF THE DECISION TREE BASE ON THE MODEL REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00c678b",
   "metadata": {},
   "source": [
    "In this model I Have implemented decision tree for the regression problem.I aim to find to best split and because of that I have used SSR(Sum Squared Residuals). I have used TSE(Total Squared Error) but its results are worst than SSR. Therefore I have chosen SSR in my model.My dataset it so big for classification. So That my run time is too bad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5eb909",
   "metadata": {},
   "source": [
    "# Implementation Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb3c05e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
